# -*- coding: utf-8 -*-
"""code_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16OZwYFy_svwr498VuabJow9iM9mAWlZb
"""

!pip install requests
!pip install transformers
!pip install sentence_transformers

import requests
import csv

url = "https://docs.google.com/spreadsheets/d/e/2PACX-1vSC0dOhvlVgYO9XcPv7qg68xGzSPphj7PrPiM0z9M3HxF5JS677dbgV44clx7NuVRG_SepAzMm4feBC/pub?output=csv"
response = requests.get(url)
if response.status_code == 200:
    csv_content = response.text
    with open("student_data.csv", "w", newline='') as csv_file:
        csv_file.write(csv_content)

url = "https://docs.google.com/spreadsheets/d/e/2PACX-1vRHpYw-aN4tkA9lrG2hWe_i9PQLo1T3A8_ODqn-_co2AUrwUXSD0KJ5IqLcFyxtUdiKBk8qwbBCPOaC/pub?gid=1944232338&single=true&output=csv"
response = requests.get(url)
if response.status_code == 200:
    csv_content = response.text
    with open("prof_data.csv", "w", newline='') as csv_file:
        csv_file.write(csv_content)

import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer, util

df1 = pd.read_csv('/content/student_data.csv')
df2 = pd.read_csv('/content/prof_data.csv')
df2['List_Column'] = df2['SKILLS'].str.split(',')
first_row_list = df2.at[0, 'List_Column']

embedding_model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')
embeddings = embedding_model.encode(df1['SKILLS'].tolist(), convert_to_tensor=True)
top_matches = {skill: [] for skill in first_row_list}

import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer, util

# Sample Dataset 1
people_skills = [{'name': 'John', 'skills': 'Python, Java, C++'},
                 {'name': 'Mary', 'skills': 'JavaScript, React, C'},
                 {'name': 'Mark', 'skills': 'Python, Flask, R'},
                 {'name': 'Sarah', 'skills': 'Java, SQL, PHP'},
                 {'name': 'Michael', 'skills': 'C++, Python, Linux'},
                 {'name': 'Alice', 'skills': 'JavaScript, HTML, CSS'}]

# Sample Dataset 2
target_skills = ['JavaScript', 'Python', 'C++', 'Big Data', 'SQL']

# Convert to Pandas DataFrames
df1 = pd.read_csv('/content/dataset_1_skills.csv')
df2 = pd.DataFrame({'target_skills': target_skills})

# Load the sentence embeddings model (DistilBERT-based)
embedding_model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')

# Generate embeddings for dataset 1
embeddings = embedding_model.encode(df1['skills'].tolist(), convert_to_tensor=True)

# Create a dictionary to store matching names for each target skill
top_matches = {skill: [] for skill in target_skills}

for idx, skill in enumerate(target_skills):
    skill_embedding = embedding_model.encode(skill, convert_to_tensor=True)

    # Calculate cosine similarities
    scores = util.pytorch_cos_sim(embeddings, skill_embedding)

    # Find all indices with similarity above a threshold (e.g., 0.7)
    threshold = 0.7
    matching_indices = np.where(scores > threshold)[0]

    # Get the names of people with matching skills
    matching_names = df1['name'].iloc[matching_indices].tolist()

    top_matches[skill] = matching_names

# Display the DataFrames
print("DataFrame 1:")
print(df1)
print("\nDataFrame 2:")
print(df2)

# Display the top matches
print("\nTop Matches:")
for skill, names in top_matches.items():
    print(f"Skill: {skill}, Matching Names: {', '.join(names)}")
    print(len(names))